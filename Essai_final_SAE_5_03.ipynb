{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j-Zxgns4Otp6",
        "hKqhGnkCPA9Y",
        "fdqGHRWCPXDI",
        "NaD6wbOSPtiZ",
        "s5s4cXx0a6o0",
        "B_AkvsLrbEhD",
        "9PyopsjubPjK",
        "8scrRNgrfNfT",
        "UuG4DUCYar1n",
        "vFFpdmr2ou6n"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Description du Notebook\n",
        "Ce notebook effectue un traitement de texte complet (nettoyage, vectorisation TF-IDF, réduction de dimension) suivi de l'application de plusieurs modèles de machine learning :\n",
        "\n",
        "1. **Random Forest** : Prédictions avec optimisation.\n",
        "2. **SVM** (Support Vector Machine) : Optimisation avec GridSearchCV.\n",
        "3. **KNN** (K-Nearest Neighbors) : Optimisation des hyperparamètres.\n",
        "4. **Logistic Regression** : Modèle de base et optimisé.\n",
        "5. **Decision Tree** : Analyse et évaluation.\n",
        "\n",
        "Chaque section inclut :\n",
        "- **Préparation des données** (nettoyage, TF-IDF, réduction de dimension).\n",
        "- **Optimisation des hyperparamètres** (GridSearchCV).\n",
        "- **Évaluation des performances** (à l'aide d'Accuracy, F1-Score, et Matrice de Confusion).\n",
        "- **Graphiques explicatifs** pour visualiser les résultats."
      ],
      "metadata": {
        "id": "ETVj2NckOjuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports et Configuration**"
      ],
      "metadata": {
        "id": "j-Zxgns4Otp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "042Rcm6KcXSk"
      },
      "outputs": [],
      "source": [
        "# Import des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Configurer l'affichage des graphiques\n",
        "plt.style.use('ggplot')\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Téléchargement des ressources linguistiques\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Charger le modèle SpaCy pour le français\n",
        "!python -m spacy download fr_core_news_sm\n",
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "stop_words = set(stopwords.words('french'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Prétraitement des Textes**\n"
      ],
      "metadata": {
        "id": "hKqhGnkCPA9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nettoyage et Lemmatisation des Textes**"
      ],
      "metadata": {
        "id": "rPkmGRmCPHSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger les données d'entrainement\n",
        "data = pd.read_json(\"train.jsonl\", lines=True)\n",
        "\n",
        "# Fonction pour nettoyer le texte\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Fonction pour la lemmatisation\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc if token.text not in stop_words and not token.is_punct])\n",
        "\n",
        "# Nettoyage et Lemmatisation\n",
        "data['cleaned_text'] = data['texte_annonce'].apply(clean_text).apply(lemmatize_text)\n",
        "print(data[['cleaned_text']].head())"
      ],
      "metadata": {
        "id": "dvOQv3xKdIhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualisation de la longueur des textes**"
      ],
      "metadata": {
        "id": "K95QgNxrPSdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Longueur des textes\n",
        "text_lengths = data['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(text_lengths, bins=50, kde=True)\n",
        "plt.title(\"Distribution de la longueur des textes nettoyés\")\n",
        "plt.xlabel(\"Nombre de mots\")\n",
        "plt.ylabel(\"Nombre de textes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g7sprwxQPQOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Vectorisation et Réduction de Dimension**"
      ],
      "metadata": {
        "id": "fdqGHRWCPXDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF + Truncated SVD**\n"
      ],
      "metadata": {
        "id": "MBpF3FEVPcGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorisation TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(data['cleaned_text'])\n",
        "\n",
        "# Réduction de dimension avec SVD\n",
        "svd = TruncatedSVD(n_components=100)\n",
        "X_reduced = svd.fit_transform(X_tfidf)\n",
        "\n",
        "# Variables additionnelles\n",
        "data['text_length'] = data['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "data['contains_url'] = data['texte_annonce'].apply(lambda x: 1 if 'http' in x else 0)\n",
        "data['contains_numbers'] = data['texte_annonce'].apply(lambda x: 1 if re.search(r'\\d', x) else 0)\n",
        "\n",
        "# Fusionner les variables\n",
        "top_features = ['text_length', 'contains_url', 'contains_numbers']\n",
        "additional_features = data[top_features].values\n",
        "X_final = np.hstack((X_reduced, additional_features))\n",
        "\n",
        "print(f\"Dimensions de X_final : {X_final.shape}\")"
      ],
      "metadata": {
        "id": "gWYCVjdVPgSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporter le DataFrame prétraité en CSV\n",
        "# Adding the escapechar parameter to handle special characters\n",
        "data.to_csv(\"data_preprocessed.csv\", index=False, escapechar='\\\\')\n",
        "\n",
        "# Ou, pour un fichier binaire plus rapide à charger\n",
        "data.to_pickle(\"data_preprocessed.pkl\")"
      ],
      "metadata": {
        "id": "Td4FobOvqaLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher le DataFrame transformé\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk0JXcPugekw",
        "outputId": "eeeeb298-abb8-4280-b244-3e254818c1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   OGC_FID boamp_id_annonce boamp_parent_annonce  \\\n",
            "0     9723        23-177335                 None   \n",
            "1    10502         24-63002                 None   \n",
            "2    10900         24-94957         ['24-79402']   \n",
            "3      779        23-179664                 None   \n",
            "4     5614         24-69326                 None   \n",
            "\n",
            "                                   boamp_theme_boamp boamp_libelle_annonce  \\\n",
            "0                                      Espaces verts        Avis de marché   \n",
            "1                      Station d'épuration (travaux)        Avis de marché   \n",
            "2                           Voirie et réseaux divers          Rectificatif   \n",
            "3  Prestations de services, Délégation de service...        Avis de marché   \n",
            "4                                        Génie civil        Avis de marché   \n",
            "\n",
            "  boamp_statut_annonce boamp_date_fin_de_marche  \\\n",
            "0              INITIAL               2024-02-02   \n",
            "1              INITIAL               2024-08-08   \n",
            "2         RECTIFICATIF               2024-08-23   \n",
            "3              INITIAL               2024-04-16   \n",
            "4              INITIAL               2024-07-11   \n",
            "\n",
            "  boamp_num_departement_diffusion  \\\n",
            "0                              31   \n",
            "1                              09   \n",
            "2                              33   \n",
            "3                              75   \n",
            "4                              43   \n",
            "\n",
            "                                  boamp_nom_acheteur boamp_siret_acheteur  \\\n",
            "0                                 TOULOUSE METROPOLE       24310051800170   \n",
            "1  Syndicat Mixte Départemental de l'Eau et de l'...       25090187300019   \n",
            "2                                 Bordeaux Métropole       24330031600011   \n",
            "3                                     Ville de Paris                        \n",
            "4                      Département de la Haute-Loire       22430001200016   \n",
            "\n",
            "   ... cal_num_departement_exec cal_siren_epci cal_insee_commune_exec  \\\n",
            "0  ...                       31      243100518                  31555   \n",
            "1  ...                        9                                 09332   \n",
            "2  ...                       33      243300316                  33063   \n",
            "3  ...                       75                                 75056   \n",
            "4  ...                       43                                 43020   \n",
            "\n",
            "  cal_nom_commune_exec   cal_adresse_annonce  \\\n",
            "0             TOULOUSE  DÉCHÈTERIE DU RAMIER   \n",
            "1            VERNIOLLE                         \n",
            "2             BORDEAUX    ÉGLISE SAINT LOUIS   \n",
            "3                PARIS                         \n",
            "4        BAS EN BASSET                BASSET   \n",
            "\n",
            "                                       texte_annonce  \\\n",
            "0   Avis n° 23-177335\\n \\nAttention : les informa...   \n",
            "1   1/3\\nAvis de marché\\nAttention : les informat...   \n",
            "2   1/1\\nAvis rectificatif\\nAttention : les infor...   \n",
            "3   Avis n° 23-179664\\n \\nAttention : les informa...   \n",
            "4   1/2\\nAvis de marché\\nAttention : les informat...   \n",
            "\n",
            "                                        cleaned_text text_length contains_url  \\\n",
            "0  avis attention information contenu lextrer pdf...        1982            1   \n",
            "1  avis march attention information contenu lextr...         612            1   \n",
            "2  avis rectificatif attention information conten...         132            1   \n",
            "3  avis attention information contenu lextrer pdf...        1303            1   \n",
            "4  avis march attention information contenu lextr...         362            1   \n",
            "\n",
            "  contains_numbers  \n",
            "0                1  \n",
            "1                1  \n",
            "2                1  \n",
            "3                1  \n",
            "4                1  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Modèles de Machine Learning**\n"
      ],
      "metadata": {
        "id": "-ZWqHJSsPni4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1 Modèle K-Nearest Neighbors Optimisé**"
      ],
      "metadata": {
        "id": "NaD6wbOSPtiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier .pkl\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "\n",
        "\n",
        "# Définir la variable cible\n",
        "y = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Séparer les données en ensemble d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialiser le modèle de K-NN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Définir les paramètres à tester\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],   # Nombre de voisins\n",
        "    'weights': ['uniform', 'distance'],  # Pondération des voisins\n",
        "    'p': [1, 2]  # Distance de Minkowski : 1 = Manhattan, 2 = Euclidienne\n",
        "}\n",
        "\n",
        "# Configurer la recherche par grille\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Exécuter la recherche par grille\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Meilleurs paramètres et score\n",
        "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
        "print(\"Meilleur score de validation:\", grid_search.best_score_)\n",
        "\n",
        "# Entraîner le modèle K-NN optimisé\n",
        "best_knn = grid_search.best_estimator_\n",
        "y_pred = best_knn.predict(X_test)\n",
        "\n",
        "# Évaluer les performances\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec K-NN optimisé:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-2-UYJ2vHNX",
        "outputId": "0de7bd98-1421-4a8d-9755-73e382ac532d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [    nan 0.6385  0.6385  0.639       nan 0.7275  0.67775 0.67725     nan\n",
            " 0.64    0.69625 0.69625     nan 0.7275  0.70775 0.70775     nan 0.72725\n",
            " 0.71025 0.71025]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meilleurs paramètres: {'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
            "Meilleur score de validation: 0.7275\n",
            "Accuracy avec K-NN optimisé: 0.741\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.74      1.00      0.85       741\n",
            "Rejete (hors specs)       0.00      0.00      0.00       259\n",
            "\n",
            "           accuracy                           0.74      1000\n",
            "          macro avg       0.37      0.50      0.43      1000\n",
            "       weighted avg       0.55      0.74      0.63      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans un premier temps, nous avons testé le modèle des K plus proches voisins (KNN) en optimisant plusieurs paramètres : le nombre de voisins (3, 5, 7), le type de distance (Manhattan ou Euclidienne) et la pondération des voisins (uniforme ou en fonction de la distance). Après une recherche par grille avec validation croisée, la meilleure configuration obtenue est 5 voisins, la distance de Manhattan et une pondération par distance.\n",
        "Le modèle atteint une accuracy de 74 %, principalement grâce à sa capacité à bien prédire les annonces \"Pris en compte\", qui dominent les données. En revanche, il échoue presque totalement sur la classe \"Rejetés\", avec des scores de précision et de rappel proches de zéro. Cela montre que le modèle favorise systématiquement la classe majoritaire, ce qui limite sa performance dans un contexte de données déséquilibrées.\n",
        "Même après optimisation, le KNN ne semble pas adapté pour ce problème. Il serait donc intéressant d'explorer des modèles plus robustes comme la Régression Logistique ou la Forêt Aléatoire, qui gèrent mieux les déséquilibres de classes."
      ],
      "metadata": {
        "id": "jUcpa1Ex-HQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2 Modèle LogisticRegression Optimisé**"
      ],
      "metadata": {
        "id": "s5s4cXx0a6o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assurons-nous que 'X_tfidf' est bien défini\n",
        "# Exemple (décommenter si nécessaire) :\n",
        "# tfidf_vectorizer = TfidfVectorizer()\n",
        "# X_tfidf = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# Définir la variable cible\n",
        "y = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Séparer les données en ensemble d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialiser le modèle de régression logistique\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Définir les paramètres à tester\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],               # Paramètre de régularisation\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],      # Type de régularisation\n",
        "    'solver': ['saga'],                         # Saga fonctionne avec l1, l2 et elasticnet\n",
        "    'l1_ratio': [0, 0.5, 1]                     # Ratio pour elasticnet, 0 pour l2, 1 pour l1\n",
        "}\n",
        "\n",
        "# Configurer la recherche par grille\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Exécuter la recherche par grille\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Meilleurs paramètres et score\n",
        "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
        "print(\"Meilleur score de validation:\", grid_search.best_score_)\n",
        "\n",
        "# Entraîner le modèle de régression logistique optimisé\n",
        "best_log_reg = grid_search.best_estimator_\n",
        "y_pred = best_log_reg.predict(X_test)\n",
        "\n",
        "# Évaluer les performances\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec Régression Logistique optimisée:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n"
      ],
      "metadata": {
        "id": "tKq1RyS6wdJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous passons à l'application du modèle de régression logistique. Une fois le code optimisé, on obtient les paramètres {'C': 10, 'l1_ratio': 0, 'penalty': 'l2', 'solver': 'saga'}. Nous sommes conscients qu'avec une régularisation à 10 (ce qui est plutôt grand), nous ajustons un peu mieux nos données (risque de surapprentissage) et les autres paramètres assurent également que le modèle est capable s'adapter à n'importe quelles données sans grands changements. Contrairement au modèle knn, les \"rejeté\" sont bien mieux détectés.\n",
        "\n"
      ],
      "metadata": {
        "id": "kMlyVHk0FfAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiser le modèle de régression logistique avec les meilleurs paramètres\n",
        "best_log_reg = LogisticRegression(C=10, l1_ratio=0, penalty='l2', solver='saga', max_iter=1000)\n",
        "\n",
        "# Entraîner le modèle avec les données d'entraînement\n",
        "best_log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Faire des prédictions sur les données de test\n",
        "y_pred = best_log_reg.predict(X_test)\n",
        "\n",
        "# Évaluer les performances du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec Régression Logistique optimisée:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gynMt9iuswC5",
        "outputId": "f2562cc9-f825-4a81-ef3b-985afce6985a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy avec Régression Logistique optimisée: 0.77\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.77      0.98      0.86       741\n",
            "Rejete (hors specs)       0.74      0.17      0.28       259\n",
            "\n",
            "           accuracy                           0.77      1000\n",
            "          macro avg       0.75      0.58      0.57      1000\n",
            "       weighted avg       0.76      0.77      0.71      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ainsi, nous pouvons voir que le modèle de régression logistique affiche un accuracy score de 0.77."
      ],
      "metadata": {
        "id": "LFrw3AsSWX9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3 Modèle DecisionTreeClassifier Optimisé**"
      ],
      "metadata": {
        "id": "B_AkvsLrbEhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cal_réponse_signalement est notre variable cible\n",
        "y = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Séparer les données en ensemble d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialiser le modèle d'arbre de décision\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Définir les paramètres à tester\n",
        "param_grid = {\n",
        "    'max_depth': [5, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Configurer et exécuter la recherche par grille\n",
        "grid_search = GridSearchCV(tree, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Meilleurs paramètres et score\n",
        "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
        "print(\"Meilleur score de validation:\", grid_search.best_score_)\n",
        "\n",
        "# Entraîner le modèle optimisé avec les meilleurs paramètres\n",
        "best_tree = grid_search.best_estimator_\n",
        "y_pred = best_tree.predict(X_test)\n",
        "\n",
        "# Évaluer les performances\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec Arbre de Décision optimisé:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd9CJxb__JQA",
        "outputId": "21a5fcb8-122d-45e3-9f75-8a896e117e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meilleurs paramètres: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
            "Meilleur score de validation: 0.7220000000000001\n",
            "Accuracy avec Arbre de Décision optimisé: 0.76\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.77      0.96      0.86       741\n",
            "Rejete (hors specs)       0.61      0.20      0.30       259\n",
            "\n",
            "           accuracy                           0.76      1000\n",
            "          macro avg       0.69      0.58      0.58      1000\n",
            "       weighted avg       0.73      0.76      0.71      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce code, l'objectif était d'optimiser les paramètres d'un modèle DecisionTreeClassifier en utilisant GridSearchCV. On commence par diviser les données en deux ensembles : 80% pour l’entraînement et 20% pour le test, ce qui permet d’évaluer correctement les performances du modèle sur des données qu’il n’a jamais vues. Ensuite, on définit une grille de paramètres pour tester différentes configurations : la profondeur maximale de l’arbre (max_depth), le nombre minimal d'échantillons pour diviser un nœud (min_samples_split) et le nombre minimal d'échantillons par feuille (min_samples_leaf). GridSearchCV s’occupe d’évaluer toutes les combinaisons possibles grâce à une validation croisée pour trouver les meilleurs réglages. À la fin de l’optimisation, les meilleurs paramètres obtenus sont max_depth=5, min_samples_leaf=4 et min_samples_split=10.\n",
        "\n",
        "Le modèle est ensuite testé sur l’ensemble de test avec une accuracy de 0.76, ce qui est plutôt satisfaisant. On remarque que la classe \"Pris en compte\" est très bien prédite avec un recall de 96%, tandis que la classe \"Rejeté\" pose plus de difficultés avec un recall de seulement 20%. Cela indique que le modèle est efficace pour détecter la classe majoritaire, mais il a du mal à reconnaître correctement les échantillons appartenant à la classe minoritaire."
      ],
      "metadata": {
        "id": "Vpf1OibTX1A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Meilleurs paramètres: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD, NMF\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Initialiser le modèle d'arbre de décision avec les meilleurs paramètres\n",
        "best_tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=4, min_samples_split=10, random_state=42)\n",
        "\n",
        "# Entraîner le modèle avec les données d'entraînement\n",
        "best_tree.fit(X_train, y_train)\n",
        "\n",
        "# Faire des prédictions sur les données de test\n",
        "y_pred = best_tree.predict(X_test)\n",
        "\n",
        "# Évaluer les performances du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec Arbre de Décision optimisé (avec meilleurs paramètres):\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46sem4mWtDTU",
        "outputId": "834f7abd-74ef-432b-a298-a863c93080bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy avec Arbre de Décision optimisé (avec meilleurs paramètres): 0.749\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.77      0.94      0.85       741\n",
            "Rejete (hors specs)       0.54      0.21      0.30       259\n",
            "\n",
            "           accuracy                           0.75      1000\n",
            "          macro avg       0.66      0.57      0.58      1000\n",
            "       weighted avg       0.71      0.75      0.71      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les résultats montrent une accuracy de 0.749, ce qui est très proche du score précédent. Comme dans le code précèdent, on observe que la classe \"Pris en compte\" est très bien prédite avec un recall de 94%, tandis que la classe \"Rejeté\" reste difficile à détecter avec seulement 21% de recall. Malgré l'optimisation des paramètres, ce déséquilibre persistant entre les classes montre que le modèle a tendance à favoriser la classe majoritaire. Cela peut s'expliquer par un déséquilibre dans les données où les échantillons \"Pris en compte\" sont beaucoup plus nombreux."
      ],
      "metadata": {
        "id": "LQN9-EsRYBzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4 Modèle RandomForestClassifier Optimisé**"
      ],
      "metadata": {
        "id": "9PyopsjubPjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Définir la variable cible\n",
        "y = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Séparer les données en ensemble d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialiser et entraîner la forêt aléatoire\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=42)  # n_estimators est le nombre d'arbres\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "# Prédire les labels sur l'ensemble de test\n",
        "y_pred = forest.predict(X_test)\n",
        "\n",
        "# Évaluer les performances\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec Forêt Aléatoire:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ADnxo3LADUX",
        "outputId": "3d45aa9f-c3a4-4b2e-b453-9698bf1ee334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy avec Forêt Aléatoire: 0.743\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.75      0.99      0.85       741\n",
            "Rejete (hors specs)       0.57      0.03      0.06       259\n",
            "\n",
            "           accuracy                           0.74      1000\n",
            "          macro avg       0.66      0.51      0.45      1000\n",
            "       weighted avg       0.70      0.74      0.65      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce premier code, on utilise une forêt aléatoire avec des paramètres par défaut. Le modèle s'entraîne sur 80% des données et teste sur les 20% restantes. Les résultats montrent une accuracy de 74,3%, ce qui est correct. Le modèle arrive très bien à détecter les \"Pris en compte\" avec un rappel presque parfait (99%), mais il galère complètement pour les \"Rejeté\" où il n'identifie presque rien. Ce problème vient sûrement d'un déséquilibre entre les deux classes."
      ],
      "metadata": {
        "id": "ovJ-rnAvZq1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Charger le fichier .pkl\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "\n",
        "\n",
        "# Définir la variable cible\n",
        "y = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Séparer les données en ensemble d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialiser le modèle de forêt aléatoire\n",
        "forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Définir les paramètres à tester pour l'optimisation\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],           # Nombre d'arbres dans la forêt\n",
        "    'max_depth': [10, 20, None],              # Profondeur maximale de chaque arbre\n",
        "    'min_samples_split': [2, 5, 10],          # Nombre minimum d'échantillons pour diviser un nœud\n",
        "    'min_samples_leaf': [1, 2, 4]             # Nombre minimum d'échantillons par feuille\n",
        "}\n",
        "\n",
        "# Configurer et exécuter la recherche par grille\n",
        "grid_search = GridSearchCV(forest, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Meilleurs paramètres et score\n",
        "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
        "print(\"Meilleur score de validation:\", grid_search.best_score_)\n",
        "\n",
        "# Entraîner le modèle optimisé avec les meilleurs paramètres\n",
        "best_forest = grid_search.best_estimator_\n",
        "y_pred = best_forest.predict(X_test)\n",
        "\n",
        "# Évaluer les performances\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec Forêt Aléatoire optimisée:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "S-HITouwARv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8273d50-20ed-4f34-8303-74a439a360fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meilleurs paramètres: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Meilleur score de validation: 0.728\n",
            "Accuracy avec Forêt Aléatoire optimisée: 0.745\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.75      0.99      0.85       741\n",
            "Rejete (hors specs)       0.62      0.04      0.07       259\n",
            "\n",
            "           accuracy                           0.74      1000\n",
            "          macro avg       0.69      0.52      0.46      1000\n",
            "       weighted avg       0.72      0.74      0.65      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce deuxième code, on optimise la forêt aléatoire grâce à GridSearchCV, ce qui permet de tester plusieurs paramètres comme le nombre d'arbres, la profondeur et les critères de division. À la fin, on obtient une forêt plus efficace avec les meilleurs paramètres trouvés. L'accuracy monte à 74,5%, donc il y a une petite amélioration. Encore une fois, le modèle détecte très bien les \"Pris en compte\", mais il a toujours du mal avec les \"Rejeté\", même si on gagne légèrement en précision. L'optimisation aide un peu, mais pour vraiment améliorer les résultats sur la classe \"Rejeté\", il faudrait tester d'autres approches."
      ],
      "metadata": {
        "id": "53Qj_z1iZw3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Meilleurs paramètres: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
        "\n",
        "# Initialiser le modèle de forêt aléatoire avec les meilleurs paramètres\n",
        "best_forest = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42)\n",
        "\n",
        "# Entraîner le modèle avec les données d'entraînement\n",
        "best_forest.fit(X_train, y_train)\n",
        "\n",
        "# Faire des prédictions sur les données de test\n",
        "y_pred = best_forest.predict(X_test)\n",
        "\n",
        "# Évaluer les performances du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy avec Forêt Aléatoire optimisée (avec meilleurs paramètres):\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEPo0ejjtWzs",
        "outputId": "f218e84b-1b1d-481b-d00b-54209d8b7a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy avec Forêt Aléatoire optimisée (avec meilleurs paramètres): 0.748\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.75      1.00      0.85       741\n",
            "Rejete (hors specs)       0.82      0.03      0.07       259\n",
            "\n",
            "           accuracy                           0.75      1000\n",
            "          macro avg       0.78      0.52      0.46      1000\n",
            "       weighted avg       0.77      0.75      0.65      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5 Modèle SVM Optimisé**"
      ],
      "metadata": {
        "id": "8scrRNgrfNfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# --- Étape 1 : Charger les données d'entraînement ---\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "y_train = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# --- Étape 2 : Vectoriser les textes d'entraînement ---\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
        "X_train = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# --- Étape 3 : Définir et optimiser le modèle SVM ---\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto', 0.01, 0.1],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "grid_search = GridSearchCV(svm, param_grid, scoring='f1_weighted', cv=5)\n",
        "\n",
        "# Recherche des meilleurs paramètres\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
        "print(\"Meilleur score de validation :\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "fkjZQv7lfZPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On commence par charger les données prétraitées et on utilise TF-IDF pour transformer les textes en vecteurs numériques. Ensuite, on définit une grille d’hyperparamètres (C, gamma, et kernel) pour tester différentes configurations du modèle SVM. On utilise GridSearchCV pour trouver les meilleurs paramètres en maximisant le score F1 pondéré sur 5 validations croisées. À la fin, on affiche les meilleurs paramètres et le score obtenu."
      ],
      "metadata": {
        "id": "Bdj5iysfgMrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- Étape 1 : Charger les données d'entraînement ---\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "y_train = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# --- Étape 2 : Vectoriser les textes d'entraînement ---\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
        "X_train = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# --- Étape 3 : Entraîner le modèle SVM avec les meilleurs paramètres ---\n",
        "best_svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "best_svm.fit(X_train, y_train)\n",
        "\n",
        "# --- Étape 4 : Évaluation sur les données d'entraînement ---\n",
        "y_train_pred = best_svm.predict(X_train)\n",
        "print(\"Classification Report sur l'ensemble d'entraînement :\")\n",
        "print(classification_report(y_train, y_train_pred))\n"
      ],
      "metadata": {
        "id": "yBSI4qSJfdrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après avoir trouvé les meilleurs paramètres, on initialise un modèle SVM avec ces valeurs optimisées. On entraîne ce modèle sur les données prétraitées d’entraînement transformées avec TF-IDF. Ensuite, on réalise des prédictions sur les mêmes données d’entraînement pour vérifier les performances du modèle, et on affiche un rapport de classification pour analyser les résultats."
      ],
      "metadata": {
        "id": "OtqrOcKwgS6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Exportation des prédictions**\n"
      ],
      "metadata": {
        "id": "UuG4DUCYar1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Charger les données prétraitées d'entraînement\n",
        "data_preprocessed = pd.read_pickle(\"/content/data_preprocessed.pkl\")\n",
        "\n",
        "# Définir la variable cible\n",
        "y_train = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Créer la matrice TF-IDF pour les données d'entraînement\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# Initialiser et entraîner le modèle de régression logistique avec les paramètres optimisés\n",
        "log_reg = LogisticRegression(C=10, penalty='l2', solver='saga', max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Charger et prétraiter les données de test\n",
        "test_data = pd.read_json(\"/content/test.jsonl\", lines=True)\n",
        "test_data['cleaned_text'] = test_data['texte_annonce'].str.lower().str.replace(r'[^a-z\\s]', '', regex=True)\n",
        "\n",
        "# Transformer les données de test en utilisant le même vectoriseur TF-IDF\n",
        "X_test = tfidf_vectorizer.transform(test_data['cleaned_text'])\n",
        "\n",
        "# Effectuer les prédictions sur les données de test\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Ajouter les prédictions au DataFrame de test pour référence\n",
        "test_data['predictions'] = y_pred\n",
        "\n",
        "# Exporter les prédictions pour les données de test dans un fichier CSV\n",
        "test_data[['texte_annonce', 'predictions']].to_csv(\"test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Les prédictions ont été enregistrées dans le fichier 'test_predictions.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkMsciBKFT_u",
        "outputId": "f8e506ba-65fd-476f-96fb-a36131fb010f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les prédictions ont été enregistrées dans le fichier 'test_predictions.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code entraîne un modèle de régression logistique optimisé avec TF-IDF sur les données d'entraînement. Les données de test sont nettoyées, vectorisées avec le même TF-IDF, puis utilisées pour faire des prédictions. Les résultats sont ajoutés au DataFrame et exportés dans un fichier CSV prêt pour soumission."
      ],
      "metadata": {
        "id": "bLLTjA2Nce7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Charger les données d'entraînement prétraitées\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "y_train = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Vectoriser les données d'entraînement\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# Charger et prétraiter les données de test\n",
        "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
        "test_data['cleaned_text'] = test_data['texte_annonce'].str.lower().str.replace(r'[^a-z\\s]', '', regex=True)\n",
        "\n",
        "# Transformer les données de test avec le même vectoriseur TF-IDF\n",
        "X_test = tfidf_vectorizer.transform(test_data['cleaned_text'])\n",
        "\n",
        "# Initialiser et entraîner le modèle de régression logistique\n",
        "log_reg = LogisticRegression(C=10, penalty='l2', solver='saga', max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Prédire les valeurs pour cal_réponse_signalement\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Ajouter les prédictions dans le DataFrame de test\n",
        "test_data['cal_réponse_signalement'] = y_pred\n",
        "\n",
        "# Créer le fichier final avec uniquement les colonnes OCG_FID et cal_réponse_signalement\n",
        "final_output = test_data[['OGC_FID', 'cal_réponse_signalement']]\n",
        "\n",
        "# Exporter le fichier final en CSV\n",
        "final_output.to_csv(\"final_test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Le fichier 'final_test_predictions.csv' a été généré avec succès.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kufwuw8KHCuk",
        "outputId": "d05c8386-ba40-4107-93d5-07665f3ba3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier 'final_test_predictions.csv' a été généré avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code utilise un modèle de régression logistique optimisé pour prédire la colonne cible à partir des données de test. Après le nettoyage et la vectorisation TF-IDF des textes, les prédictions sont ajoutées au DataFrame avec les colonnes requises, puis exportées en CSV pour une utilisation finale."
      ],
      "metadata": {
        "id": "DcEd_j5hc0hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Charger les données d'entraînement prétraitées\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "y_train = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Vectoriser les données d'entraînement\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# Charger et prétraiter les données de test\n",
        "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
        "test_data['cleaned_text'] = test_data['texte_annonce'].str.lower().str.replace(r'[^a-z\\s]', '', regex=True)\n",
        "\n",
        "# Transformer les données de test avec le même vectoriseur TF-IDF\n",
        "X_test = tfidf_vectorizer.transform(test_data['cleaned_text'])\n",
        "\n",
        "# Initialiser le modèle de forêt aléatoire avec les meilleurs paramètres\n",
        "best_forest = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42)\n",
        "\n",
        "# Entraîner le modèle avec les données d'entraînement\n",
        "best_forest.fit(X_train, y_train)\n",
        "\n",
        "# Prédire les valeurs pour cal_réponse_signalement\n",
        "y_pred = best_forest.predict(X_test)\n",
        "\n",
        "# Ajouter les prédictions dans le DataFrame de test\n",
        "test_data['cal_réponse_signalement'] = y_pred\n",
        "\n",
        "# Créer le fichier final avec uniquement les colonnes OGC_FID et cal_réponse_signalement\n",
        "final_output = test_data[['OGC_FID', 'cal_réponse_signalement']]\n",
        "\n",
        "# Exporter le fichier final en CSV\n",
        "final_output.to_csv(\"final_test_predictions_forest.csv\", index=False)\n",
        "\n",
        "print(\"Le fichier 'final_test_predictions_forest.csv' a été généré avec succès.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg3Bw8TxEbFu",
        "outputId": "c683f3e3-b663-46ff-8250-322b844957c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier 'final_test_predictions_forest.csv' a été généré avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code utilise un Random Forest optimisé pour prédire les valeurs cibles. Il commence par vectoriser les textes en utilisant TF-IDF, puis entraîne le modèle avec les meilleurs hyperparamètres trouvés. Les prédictions sont ajoutées au DataFrame de test et exportées dans un fichier CSV contenant uniquement les colonnes OGC_FID et cal_réponse_signalement."
      ],
      "metadata": {
        "id": "wsJ1fDRAdDoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "import re\n",
        "\n",
        "# --- Étape 1 : Charger les données prétraitées d'entraînement ---\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "y_train = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# --- Étape 2 : Vectoriser les textes d'entraînement ---\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
        "X_train = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# --- Étape 3 : Charger les données de test ---\n",
        "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
        "\n",
        "# Nettoyer les textes de test\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Supprimer caractères spéciaux et chiffres\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "test_data['cleaned_text'] = test_data['texte_annonce'].apply(clean_text)\n",
        "\n",
        "# Transformer les textes de test avec le vectoriseur TF-IDF déjà entraîné\n",
        "X_test = tfidf_vectorizer.transform(test_data['cleaned_text'])\n",
        "\n",
        "# --- Étape 4 : Entraîner et utiliser le modèle optimisé ---\n",
        "best_svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "best_svm.fit(X_train, y_train)\n",
        "\n",
        "# Prédire les résultats pour les données de test\n",
        "y_test_pred = best_svm.predict(X_test)\n",
        "\n",
        "# Ajouter les prédictions dans le DataFrame de test\n",
        "test_data['cal_réponse_signalement'] = y_test_pred\n",
        "\n",
        "# --- Étape 5 : Exporter les prédictions ---\n",
        "final_output = test_data[['OGC_FID', 'cal_réponse_signalement']]\n",
        "final_output.to_csv(\"final_svm_test_predictions.csv\", index=False)\n",
        "print(\"Le fichier 'final_svm_test_predictions.csv' a été généré avec succès.\")\n"
      ],
      "metadata": {
        "id": "z0s01O3efmgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On reprend les données prétraitées et on applique TF-IDF pour les vectoriser, tout comme pour l’entraînement. Les textes des données de test sont nettoyés et transformés avec le même vectoriseur TF-IDF. On utilise le modèle SVM optimisé pour faire des prédictions sur les données de test. Les prédictions sont ajoutées au DataFrame des données de test, puis exportées dans un fichier CSV final pour une analyse ultérieure."
      ],
      "metadata": {
        "id": "5lmuEP_ygWBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie Brouillon + Test supplémentaire pour Optimisation sans réel succès"
      ],
      "metadata": {
        "id": "vFFpdmr2ou6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier .pkl\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "\n",
        "# Définir la variable cible\n",
        "y = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Supprimer les colonnes inutiles (par exemple, identifiants ou colonnes textuelles longues)\n",
        "columns_to_drop = ['OGC_FID', 'texte_annonce']  # Ajuster selon vos données\n",
        "X = data_preprocessed.drop(columns=columns_to_drop + ['cal_réponse_signalement'], errors='ignore')\n",
        "\n",
        "# Identifier les colonnes qualitatives restantes et les encoder si nécessaire\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
        "label_encoder = LabelEncoder()\n",
        "for col in non_numeric_columns:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "# Séparer les données en ensemble d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Étape 1 : Réduction des variables avec RandomForestClassifier ---\n",
        "# Entraîner un modèle de forêt aléatoire pour évaluer l'importance des variables\n",
        "forest = RandomForestClassifier(random_state=42)\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "# Importance des variables\n",
        "importances = forest.feature_importances_\n",
        "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
        "print(\"\\nTop 10 variables importantes :\\n\", importance_df.head(10))\n",
        "\n",
        "# Réduire les variables en ne gardant que celles au-dessus d'un seuil d'importance\n",
        "threshold = 0.01\n",
        "important_features = importance_df[importance_df['Importance'] > threshold]['Feature'].tolist()\n",
        "X_train_reduced = X_train[important_features]\n",
        "X_test_reduced = X_test[important_features]\n",
        "\n",
        "# Vérifier les dimensions après réduction\n",
        "print(f\"\\nNombre de colonnes après réduction : {X_train_reduced.shape[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU6FoYS1hGlc",
        "outputId": "296deaa1-7a7a-4be0-8aea-51dadaafb04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 variables importantes :\n",
            "                             Feature  Importance\n",
            "11                   boamp_intitule    0.065873\n",
            "2                 boamp_theme_boamp    0.057482\n",
            "7                boamp_nom_acheteur    0.054459\n",
            "22           cal_insee_commune_exec    0.054423\n",
            "25                     cleaned_text    0.052405\n",
            "16                   cal_mot_rang_1    0.052240\n",
            "17                   cal_mot_rang_2    0.051991\n",
            "6   boamp_num_departement_diffusion    0.051126\n",
            "26                      text_length    0.050604\n",
            "23             cal_nom_commune_exec    0.050174\n",
            "\n",
            "Nombre de colonnes après réduction : 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Réentraîner le modèle avec les données originales et gestion des poids\n",
        "forest_weighted = RandomForestClassifier(\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    n_estimators=50,\n",
        "    class_weight='balanced',  # Gestion automatique des poids\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Entraîner le modèle\n",
        "forest_weighted.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Faire des prédictions sur les données de test\n",
        "y_pred_weighted = forest_weighted.predict(X_test_reduced)\n",
        "\n",
        "# Évaluer les performances\n",
        "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
        "report_weighted = classification_report(y_test, y_pred_weighted)\n",
        "\n",
        "print(\"\\n--- Résultats avec Forêt Aléatoire et Gestion des Poids ---\")\n",
        "print(\"Accuracy :\", accuracy_weighted)\n",
        "print(\"\\nClassification Report:\\n\", report_weighted)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF4IT3KdR9HO",
        "outputId": "f2def932-f494-4fb1-fdd4-e654adddbaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Résultats avec Forêt Aléatoire et Gestion des Poids ---\n",
            "Accuracy : 0.753\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "     Pris en compte       0.76      0.98      0.85       741\n",
            "Rejete (hors specs)       0.63      0.11      0.19       259\n",
            "\n",
            "           accuracy                           0.75      1000\n",
            "          macro avg       0.69      0.54      0.52      1000\n",
            "       weighted avg       0.73      0.75      0.68      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Charger les données d'entraînement prétraitées\n",
        "data_preprocessed = pd.read_pickle(\"data_preprocessed.pkl\")\n",
        "y_train = data_preprocessed['cal_réponse_signalement']\n",
        "\n",
        "# Vectoriser les données d'entraînement\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train = tfidf_vectorizer.fit_transform(data_preprocessed['cleaned_text'])\n",
        "\n",
        "# Charger et prétraiter les données de test\n",
        "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
        "test_data['cleaned_text'] = test_data['texte_annonce'].str.lower().str.replace(r'[^a-z\\s]', '', regex=True)\n",
        "\n",
        "# Transformer les données de test avec le même vectoriseur TF-IDF\n",
        "X_test = tfidf_vectorizer.transform(test_data['cleaned_text'])\n",
        "\n",
        "# Initialiser et entraîner le modèle de régression logistique\n",
        "log_reg = LogisticRegression(C=10, penalty='l2', solver='saga', max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Prédire les valeurs pour cal_réponse_signalement\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Ajouter les prédictions dans le DataFrame de test\n",
        "test_data['cal_réponse_signalement'] = y_pred\n",
        "\n",
        "# Créer le fichier final avec uniquement les colonnes OCG_FID et cal_réponse_signalement\n",
        "final_output = test_data[['OGC_FID', 'cal_réponse_signalement']]\n",
        "\n",
        "# Exporter le fichier final en CSV\n",
        "final_output.to_csv(\"final_test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Le fichier 'final_test_predictions.csv' a été généré avec succès.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGg5J2kMAsR8",
        "outputId": "d9d55606-f3b5-43a3-f657-1f4b078e1a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier 'final_test_predictions.csv' a été généré avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Charger les données de test avec la vérité terrain\n",
        "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
        "# Charger les prédictions finales\n",
        "test_predictions = pd.read_csv(\"/content/final_test_predictions.csv\")\n",
        "# Associer les prédictions aux vérités terrain en utilisant la colonne `OGC_FID`\n",
        "merged_data = test_data.merge(test_predictions, on='OGC_FID', suffixes=('_réelle', '_prédite'))\n",
        "\n",
        "# Vérifier si les colonnes nécessaires existent\n",
        "if 'cal_réponse_signalement' in merged_data.columns and 'cal_réponse_signalement_prédite' in merged_data.columns:\n",
        "    # Calculer l'accuracy\n",
        "    accuracy = accuracy_score(merged_data['cal_réponse_signalement'], merged_data['cal_réponse_signalement_prédite'])\n",
        "\n",
        "    # Générer le rapport de classification\n",
        "    report = classification_report(merged_data['cal_réponse_signalement'], merged_data['cal_réponse_signalement_prédite'])\n",
        "\n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(merged_data['cal_réponse_signalement'], merged_data['cal_réponse_signalement_prédite'])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Rejeté\", \"Pris en compte\"])\n",
        "\n",
        "    print(f\"Accuracy : {accuracy:.3f}\\n\")\n",
        "    print(\"Rapport de classification :\\n\", report)\n",
        "\n",
        "    # Afficher la matrice de confusion\n",
        "    disp.plot(cmap=\"Blues\")\n",
        "    plt.title(\"Matrice de Confusion : Modèle Final\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Les colonnes nécessaires (prédictions ou vérités terrain) ne sont pas disponibles.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K529LvWPDn68",
        "outputId": "cea376ad-8585-4b46-9d3c-06647a127262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les colonnes nécessaires (prédictions ou vérités terrain) ne sont pas disponibles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "important_features = [\n",
        "    'boamp_intitule', 'boamp_theme_boamp', 'boamp_nom_acheteur',\n",
        "    'cal_insee_commune_exec', 'cleaned_text', 'cal_mot_rang_1',\n",
        "    'cal_mot_rang_2', 'boamp_num_departement_diffusion', 'text_length',\n",
        "    'cal_nom_commune_exec'\n",
        "]\n",
        "# Les colonnes utilisées dans votre DataFrame d'entraînement\n",
        "top_29_features = X_train.columns.tolist()\n",
        "\n",
        "# Vérifiez le contenu de la liste\n",
        "print(\"Liste des 29 features utilisées dans le modèle :\")\n",
        "print(top_29_features)\n",
        "print(f\"Nombre de features : {len(top_29_features)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiC000rMxIii",
        "outputId": "a47cb6c9-7859-4a09-cdab-22232bfa4d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liste des 29 features utilisées dans le modèle :\n",
            "['boamp_id_annonce', 'boamp_parent_annonce', 'boamp_theme_boamp', 'boamp_libelle_annonce', 'boamp_statut_annonce', 'boamp_date_fin_de_marche', 'boamp_num_departement_diffusion', 'boamp_nom_acheteur', 'boamp_siret_acheteur', 'boamp_type_organisme', 'boamp_lieu_exec', 'boamp_intitule', 'cal_fichier_pdf', 'cal_num_signalement', 'cal_theme_signalement', 'cal_statut_workflow', 'cal_mot_rang_1', 'cal_mot_rang_2', 'cal_date_traitement', 'cal_type_localisation', 'cal_num_departement_exec', 'cal_siren_epci', 'cal_insee_commune_exec', 'cal_nom_commune_exec', 'cal_adresse_annonce', 'cleaned_text', 'text_length', 'contains_url', 'contains_numbers']\n",
            "Nombre de features : 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 1 : Charger les données de test\n",
        "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
        "\n",
        "# Étape 2 : Nettoyage et lemmatisation du texte\n",
        "test_data['cleaned_text'] = test_data['texte_annonce'].apply(clean_text).apply(lemmatize_text)\n",
        "\n",
        "# Étape 3 : Vectorisation avec le TF-IDF déjà entraîné\n",
        "# Important : Utiliser le vectoriseur TF-IDF ajusté sur les données d'entraînement\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_data['cleaned_text'])\n",
        "\n",
        "# Étape 4 : Réduction de dimension (SVD)\n",
        "# Important : Utiliser le modèle SVD déjà entraîné\n",
        "X_test_reduced = svd.transform(X_test_tfidf)\n",
        "\n",
        "# Étape 5 : Création des variables additionnelles\n",
        "test_data['text_length'] = test_data['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "test_data['contains_url'] = test_data['texte_annonce'].apply(lambda x: 1 if 'http' in x else 0)\n",
        "test_data['contains_numbers'] = test_data['texte_annonce'].apply(lambda x: 1 if re.search(r'\\d', x) else 0)\n",
        "\n",
        "# Étape 6 : Sélection des colonnes additionnelles et conversion en array\n",
        "additional_features = test_data[['text_length', 'contains_url', 'contains_numbers']].values\n",
        "\n",
        "# Étape 7 : Combinaison des variables réduites et additionnelles\n",
        "X_test_combined = np.hstack((X_test_reduced, additional_features))\n",
        "\n",
        "# Étape 8 : Sélection des 29 features importants\n",
        "# Important : Utiliser les mêmes features que ceux sélectionnés pour l'entraînement\n",
        "selected_features = top_29_features\n",
        "X_test_final = test_data[selected_features].values\n",
        "\n"
      ],
      "metadata": {
        "id": "9efUdrEAyi1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérification des dimensions\n",
        "if X_test_final.shape[1] != X_train.shape[1]:\n",
        "    raise ValueError(f\"Incompatibilité : X_test_final a {X_test_final.shape[1]} features, mais le modèle en attend {X_train.shape[1]}.\")\n"
      ],
      "metadata": {
        "id": "EEXR6nnA4FnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_features = [col for col in important_features if col not in test_data.columns]\n",
        "if missing_features:\n",
        "    print(f\"Colonnes manquantes dans les données de test : {missing_features}\")\n",
        "else:\n",
        "    print(\"Toutes les colonnes importantes sont disponibles.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKcDh4Hl5vDg",
        "outputId": "510a0db2-4782-47ed-e7b3-c745cc77333f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toutes les colonnes importantes sont disponibles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 9 : Faire des prédictions avec le modèle optimisé\n",
        "y_test_pred = best_forest.predict(X_test_final)\n",
        "y_test_probs = best_forest.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "# Étape 10 : Ajouter les prédictions et scores dans le DataFrame de test\n",
        "test_data['cal_réponse_signalement_prédite'] = y_test_pred\n",
        "test_data['confidence'] = y_test_probs\n",
        "\n",
        "# Étape 11 : Exporter les prédictions pour analyse\n",
        "test_data[['OGC_FID', 'cal_réponse_signalement_prédite']].to_csv(\"test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Les prédictions ont été exportées dans 'test_predictions.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "iU1crmeE3OKM",
        "outputId": "4283a91e-0c76-4e78-c14e-216283d4e8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_forest' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4f18ea4516fc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Étape 9 : Faire des prédictions avec le modèle optimisé\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Étape 10 : Ajouter les prédictions et scores dans le DataFrame de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_forest' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if X_test_final.shape[1] != X_train.shape[1]:\n",
        "    print(f\"Incompatibilité : X_test_final a {X_test_final.shape[1]} features, mais le modèle en attend {X_train.shape[1]}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSI37nEH6bYe",
        "outputId": "5518601a-aad5-4fa1-f809-d8a382824343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incompatibilité : X_test_final a 103 features, mais le modèle en attend 29.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming 'train_data' is your training data DataFrame\n",
        "# ... (your previous code to load and preprocess train_data) ...\n",
        "\n",
        "# 1. Re-fit TF-IDF Vectorizer on the combined text data of train and test sets\n",
        "all_text_data = pd.concat([train_data['cleaned_text'], test_data['cleaned_text']])\n",
        "tfidf_vectorizer = TfidfVectorizer()  # Or use your previous parameters\n",
        "tfidf_vectorizer.fit(all_text_data)\n",
        "\n",
        "# 2. Transform train and test data with the re-fitted TF-IDF Vectorizer\n",
        "X_train_tfidf = tfidf_vectorizer.transform(train_data['cleaned_text'])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_data['cleaned_text'])\n",
        "\n",
        "# 3. Re-fit SVD on the transformed training data\n",
        "svd.fit(X_train_tfidf)  # Or use your previous parameters\n",
        "\n",
        "# 4. Transform both train and test data with the re-fitted SVD\n",
        "X_train_reduced = svd.transform(X_train_tfidf)\n",
        "X_test_reduced = svd.transform(X_test_tfidf)\n",
        "\n",
        "# 5. Continue with creating and combining additional features as before\n",
        "# ... (your existing code for additional features and combining them) ...\n",
        "\n",
        "# 6. Retrain your model (best_forest) with the new transformed training data\n",
        "# ... (your existing code for model training) ...\n",
        "\n",
        "# 7. Now predict using the updated test data\n",
        "y_test_pred = best_forest.predict(X_test_final)\n",
        "# ... (rest of your prediction code) ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ocvBeRZc6Q2B",
        "outputId": "6e20f60c-0c09-4db8-8e49-09b8b78a28ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-2c78e8ca0b18>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1. Re-fit TF-IDF Vectorizer on the combined text data of train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mall_text_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Or use your previous parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_text_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# Étape 9 : Analyse des résultats (si étiquettes disponibles dans test_data)\n",
        "if 'cal_réponse_signalement' in test_data.columns:\n",
        "    print(\"\\n--- Analyse des Résultats ---\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(test_data['cal_réponse_signalement'], y_test_pred))\n",
        "\n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(test_data['cal_réponse_signalement'], y_test_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Rejeté\", \"Pris en compte\"])\n",
        "    disp.plot(cmap=\"Blues\")\n",
        "    plt.title(\"Matrice de Confusion : Forêt Aléatoire Optimisée\")\n",
        "    plt.show()\n",
        "\n",
        "    # Afficher l'Accuracy\n",
        "    accuracy = accuracy_score(test_data['cal_réponse_signalement'], y_test_pred)\n",
        "    print(f\"\\nAccuracy sur les données de test : {accuracy:.3f}\")\n",
        "\n",
        "# Étape 10 : Exporter les prédictions pour analyse\n",
        "test_data[['OGC_FID', 'cal_réponse_signalement_prédite', 'confidence']].to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"\\nLes prédictions ont été exportées dans 'test_predictions.csv'.\")\n"
      ],
      "metadata": {
        "id": "FCqcZaRN0yyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Faire des prédictions avec le modèle optimisé\n",
        "y_test_pred = best_forest.predict(X_test_final)\n",
        "y_test_probs = best_forest.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "# Ajouter les prédictions et scores dans le DataFrame de test\n",
        "test_data['cal_réponse_signalement_prédite'] = y_test_pred\n",
        "test_data['confidence'] = y_test_probs\n",
        "\n",
        "# Analyse des résultats\n",
        "print(\"\\n--- Analyse des Résultats ---\")\n",
        "if 'cal_réponse_signalement' in test_data.columns:  # Si les vraies étiquettes sont disponibles\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(test_data['cal_réponse_signalement'], y_test_pred))\n",
        "\n",
        "    # Afficher la matrice de confusion\n",
        "    cm = confusion_matrix(test_data['cal_réponse_signalement'], y_test_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Rejeté\", \"Pris en compte\"])\n",
        "    disp.plot(cmap=\"Blues\")\n",
        "    plt.title(\"Matrice de Confusion : Forêt Aléatoire Optimisée\")\n",
        "    plt.show()\n",
        "\n",
        "    # Afficher l'Accuracy\n",
        "    accuracy = accuracy_score(test_data['cal_réponse_signalement'], y_test_pred)\n",
        "    print(f\"\\nAccuracy sur les données de test : {accuracy:.3f}\")\n",
        "\n",
        "# Exporter les prédictions pour analyse\n",
        "test_data[['OGC_FID', 'cal_réponse_signalement_prédite', 'confidence']].to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"Les prédictions ont été exportées dans 'test_predictions.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "KKzoJpBoxZoD",
        "outputId": "e55ceb81-f1bc-4829-e23f-c7062ab4a57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: \"Travaux de création d'une piste cyclable située rue des Poissonniers/Cantelaude/Moulin à Le Teich\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-c30b823837cd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Faire des prédictions avec le modèle optimisé\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ajouter les prédictions et scores dans le DataFrame de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"Travaux de création d'une piste cyclable située rue des Poissonniers/Cantelaude/Moulin à Le Teich\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Charger les données de test\n",
        "test_data = pd.read_json(\"test.jsonl\", lines=True)\n",
        "\n",
        "# Réduction des variables sur les données de test\n",
        "X_test_reduced = test_data[important_features]  # Utilisez les variables importantes identifiées\n",
        "\n",
        "# Prédire les classes sur les données de test avec le modèle pondéré\n",
        "y_test_pred_weighted = forest_weighted.predict(X_test_reduced)\n",
        "\n",
        "# Ajouter les prédictions dans le DataFrame des données de test\n",
        "test_data['cal_réponse_signalement_prédite'] = y_test_pred_weighted\n",
        "\n",
        "# Exporter les prédictions\n",
        "test_data[['OGC_FID', 'cal_réponse_signalement_prédite']].to_csv(\"test_predictions_weighted.csv\", index=False)\n",
        "\n",
        "print(\"\\nLes prédictions ont été enregistrées dans 'test_predictions_weighted.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "n5HswjExwWOq",
        "outputId": "28bf51b6-7d58-44d2-d287-7176a72a9020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['cleaned_text', 'text_length'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-f09bd9b905e1>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Réduction des variables sur les données de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_test_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimportant_features\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Utilisez les variables importantes identifiées\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Prédire les classes sur les données de test avec le modèle pondéré\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['cleaned_text', 'text_length'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yxnH09V665Ab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}